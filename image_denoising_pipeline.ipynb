{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For image \n",
    "import pickle\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.util import random_noise #https://scikit-image.org/docs/dev/api/skimage.util.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIDD_Preprocessing():\n",
    "\n",
    "  def __init__(self,dataset_path):\n",
    "    self.dataset_path = dataset_path\n",
    "    self.image_size = 128\n",
    "    self.size = (self.image_size,self.image_size)\n",
    "    self.noisy_img_array = []\n",
    "    self.gt_img_array = []\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def read_images(self):\n",
    "    \n",
    "    path = self.dataset_path + '_ReadMe.txt'\n",
    "    with open(path) as f:\n",
    "        readme = f.read()\n",
    "    \n",
    "    print(readme)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def split_paths(self):\n",
    "\n",
    "    noisy_images_path = []\n",
    "    gt_images_path = []\n",
    "\n",
    "    path = self.dataset_path + 'Scene_Instances.txt'\n",
    "    with open(path) as f:\n",
    "        instances = f.read()\n",
    "\n",
    "\n",
    "    instances = instances.split('\\n')\n",
    "    diff_path = self.dataset_path + 'Data' + '/' \n",
    "\n",
    "\n",
    "    for f in instances:\n",
    "        images_path = diff_path + f + '/'\n",
    "    \n",
    "        for g in os.listdir(images_path):\n",
    "          image_path = images_path + g\n",
    "        \n",
    "          if 'NOISY' in image_path:\n",
    "              noisy_images_path.append(image_path)\n",
    "          else:\n",
    "              gt_images_path.append(image_path)\n",
    "            \n",
    "\n",
    "    print('TOTAL NOISY IMAGES:', len(noisy_images_path))\n",
    "    print('TOTAL GROUND TRUTH IMAGES:', len(gt_images_path))\n",
    "\n",
    "    return noisy_images_path , gt_images_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  def img_transformation(self, noisy_images_path, gt_images_path):\n",
    "\n",
    "\n",
    "\n",
    "    for f in tqdm(noisy_images_path):\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, self.size)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        norm = np.zeros((self.size))\n",
    "        norm_image = cv2.normalize(img,  norm, 0, 255, cv2.NORM_MINMAX)\n",
    "        self.noisy_img_array.append(norm_image)\n",
    "    \n",
    "    \n",
    "\n",
    "    for f in tqdm(gt_images_path):\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, self.size)\n",
    "\n",
    "    \n",
    "    \n",
    "        self.gt_img_array.append(img)\n",
    "\n",
    "    return self.noisy_img_array , self.gt_img_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def view_image(self, num = 10):\n",
    "\n",
    "     for i in range(0,len(self.noisy_img_array),num):\n",
    "    \n",
    "        fig=plt.figure(figsize=(50, 25))\n",
    "    \n",
    "        ax = plt.subplot(131)\n",
    "        plt.title('Ground Truth')\n",
    "        plt.imshow(self.gt_img_array[i])\n",
    "    \n",
    "        ax = plt.subplot(132)\n",
    "        plt.title('Noisy Image')\n",
    "        plt.imshow(self.noisy_img_array[i])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def train_test_split(self,):\n",
    "\n",
    "    noisy_train_set , noisy_test_set , gt_train_set , gt_test_set =  train_test_split(\n",
    "                                                                         self.noisy_img_array , self.gt_img_array, test_size=0.20, random_state=42)\n",
    "\n",
    "    noisy_train_set_tensor = tf.convert_to_tensor(noisy_train_set)\n",
    "    noisy_test_set_tensor = tf.convert_to_tensor(noisy_test_set)\n",
    "    gt_train_set_tensor = tf.convert_to_tensor(gt_train_set)\n",
    "    gt_test_set_tensor = tf.convert_to_tensor(gt_test_set)\n",
    "\n",
    "\n",
    "    print(noisy_train_set_tensor.shape)\n",
    "    print(noisy_test_set_tensor.shape)\n",
    "    print(gt_train_set_tensor.shape)\n",
    "    print(gt_test_set_tensor.shape) \n",
    "\n",
    "    \n",
    "    return noisy_train_set_tensor, noisy_test_set_tensor, gt_train_set_tensor, gt_test_set_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = SIDD_Preprocessing(dataset_path = '/content/drive/MyDrive/Colab Notebooks/SIDD_Small_sRGB_Only/')\n",
    "# obj.read_images()\n",
    "noisy_images_path , gt_images_path = obj.split_paths()\n",
    "obj.img_transformation(noisy_images_path , gt_images_path)\n",
    "noisy_train_set_tensor, noisy_test_set_tensor, gt_train_set_tensor, gt_test_set_tensor = obj.train_test_split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('3.9.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c253361ddad0a4de07aff575a0b7120d669ad16e1d613d635c59bc2ada445499"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
